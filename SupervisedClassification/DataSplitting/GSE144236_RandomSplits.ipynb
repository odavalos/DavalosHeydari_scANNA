{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd70c9af-5571-4315-8e08-bbdf8609aceb",
   "metadata": {},
   "source": [
    "# Generating the Random Splits for Model Evaluation: GSE144236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55c3721-f495-4892-9493-8fdaa728b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "813df9a5-fc0a-4145-8a79-0009f4388518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep\n",
    "dataset_name = 'GSE144236' # label for the dataset\n",
    "dictionary_dir = 'SavedSplitDicts' # dir where we save the split dictionaries\n",
    "metadata_dir = 'Metadata_Splits' # dir where we save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cb404c-9309-4ec3-a7fa-3df5a5f88bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists!\n",
      "Directory already exists!\n"
     ]
    }
   ],
   "source": [
    "# Make sure necessary directories are avalible\n",
    "\n",
    "# dictionary dir\n",
    "if not os.path.exists(dictionary_dir):\n",
    "    os.makedirs(dictionary_dir)\n",
    "    print(f\"Directory {dictionary_dir} created for saving split dictionaries\")\n",
    "    \n",
    "else:\n",
    "    print('Directory already exists!')\n",
    "\n",
    "\n",
    "# metadata dir\n",
    "if not os.path.exists(metadata_dir):\n",
    "    os.makedirs(metadata_dir)\n",
    "    print(f\"Directory {metadata_dir} created for saving metadata with the 5 splits\")\n",
    "    \n",
    "else:\n",
    "    print('Directory already exists!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee12cee-2498-4724-ba8a-e8d54c95febe",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb61123-a194-47b4-9cea-de495e64aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('GSE144236_qc_hvg_anno_5k_raw_train_split.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146ecc8b-fb6c-4c6f-8066-c75aa4bd3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adata.raw.X.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c33ed-59db-4c31-9e1d-484a05077b51",
   "metadata": {},
   "source": [
    "Generate the 5 splits using sklearn `ShuffleSplit`\n",
    "- standard 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441a344b-235f-4dcb-9e6d-4d0300193a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = ShuffleSplit(n_splits=5, test_size=.20, random_state=2022)\n",
    "rs.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29f1ab-1a05-4620-b4b5-3ec66603a42b",
   "metadata": {},
   "source": [
    "Create a list of dictionaries containing the generated splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf2ff04-ae88-4569-bc82-b591fc051504",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_list = []\n",
    "for train_index, test_index in rs.split(X):\n",
    "    split_list.append({\"train\": train_index, \"test\": test_index})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa784ff0-ebe0-4e93-9f85-1801299d5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_splits = dict(list(enumerate(split_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b44f6318-a941-4f18-8b12-22dc073502ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'train': array([11054, 30965, 42248, ..., 16557,  1244, 21373]),\n",
       "  'test': array([34717, 27820, 41304, ...,  7538, 35197,  1780])},\n",
       " 1: {'train': array([37433, 28797, 17101, ..., 28290, 33927, 23822]),\n",
       "  'test': array([ 3797, 33124, 34866, ..., 44651,   283, 14810])},\n",
       " 2: {'train': array([41661, 33172,  9029, ...,   116, 15794, 27078]),\n",
       "  'test': array([33852, 44196,  9632, ...,   458, 11384, 29039])},\n",
       " 3: {'train': array([36299, 17846, 25235, ..., 15014, 16076, 17602]),\n",
       "  'test': array([24579, 43797,  5638, ..., 41347, 10263, 25275])},\n",
       " 4: {'train': array([32429,   609, 36693, ..., 16899,  3625, 44968]),\n",
       "  'test': array([11461, 41460,  7667, ..., 42606,   803, 37816])}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e84d1-87ff-46fb-8356-c195df1ae6f5",
   "metadata": {},
   "source": [
    "Renaming the dictionaries to contain \"Split_#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8117b315-d9b0-4f77-84ab-4bb7f95c3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keys = [f'Split_{i}' for i in range(1,6)]\n",
    "dataset_splits = dict(zip(new_keys, list(dataset_splits.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a919b761-e957-40e7-b3f4-88e5afdefb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary\n",
    "def Pickler(data, filename):\n",
    "    \n",
    "    outfile = open(filename, 'wb+')\n",
    "    \n",
    "    #source destination\n",
    "    \n",
    "    pickle.dump(data, outfile)\n",
    "    \n",
    "    outfile.close()\n",
    "\n",
    "Pickler(dataset_splits, filename=f\"{dictionary_dir}/{dataset_name}_SplitDict.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee3cc5d9-f580-42af-990b-aceb06f082fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load\n",
    "\n",
    "def Unpickler(filename):\n",
    "    \n",
    "    infile = open(filename, 'rb+')\n",
    "    \n",
    "    return_file = pickle.load(infile);\n",
    "    \n",
    "    infile.close()\n",
    "\n",
    "    return return_file\n",
    "\n",
    "test_loaddict = Unpickler(filename=f\"{dictionary_dir}/{dataset_name}_SplitDict.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a610a4f6-d725-42c9-9037-807e406d6fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Split_1': {'train': array([11054, 30965, 42248, ..., 16557,  1244, 21373]),\n",
       "  'test': array([34717, 27820, 41304, ...,  7538, 35197,  1780])},\n",
       " 'Split_2': {'train': array([37433, 28797, 17101, ..., 28290, 33927, 23822]),\n",
       "  'test': array([ 3797, 33124, 34866, ..., 44651,   283, 14810])},\n",
       " 'Split_3': {'train': array([41661, 33172,  9029, ...,   116, 15794, 27078]),\n",
       "  'test': array([33852, 44196,  9632, ...,   458, 11384, 29039])},\n",
       " 'Split_4': {'train': array([36299, 17846, 25235, ..., 15014, 16076, 17602]),\n",
       "  'test': array([24579, 43797,  5638, ..., 41347, 10263, 25275])},\n",
       " 'Split_5': {'train': array([32429,   609, 36693, ..., 16899,  3625, 44968]),\n",
       "  'test': array([11461, 41460,  7667, ..., 42606,   803, 37816])}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loaddict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13d721-dce1-43cf-b3a5-96f6abeae5fb",
   "metadata": {},
   "source": [
    "#### Add split information to the adata object metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e5def49-5e98-4b92-aa4f-3bee65964372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index to have numeric rownames instead of barcodes\n",
    "adata.obs = adata.obs.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f61386e-6214-4883-8d7d-fcfa1989e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all 5 splits\n",
    "adata.obs['Split_1'] = np.where(adata.obs.index.isin(dataset_splits['Split_1']['train'].tolist()), 'train', 'test')\n",
    "adata.obs['Split_2'] = np.where(adata.obs.index.isin(dataset_splits['Split_2']['train'].tolist()), 'train', 'test')\n",
    "adata.obs['Split_3'] = np.where(adata.obs.index.isin(dataset_splits['Split_3']['train'].tolist()), 'train', 'test')\n",
    "adata.obs['Split_4'] = np.where(adata.obs.index.isin(dataset_splits['Split_4']['train'].tolist()), 'train', 'test')\n",
    "adata.obs['Split_5'] = np.where(adata.obs.index.isin(dataset_splits['Split_5']['train'].tolist()), 'train', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b06142-9a91-4813-91ef-2e7a85e8fafd",
   "metadata": {},
   "source": [
    "#### Quick sanity check on Split_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dd2ba2b-14f8-4969-8770-15a5c09504db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    37616\n",
       "test      9405\n",
       "Name: Split_1, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs['Split_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8216a254-335e-45e4-b113-4438f26fc7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random test cell: 2036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index                P1_Normal_CGACTTCCAGCTGGCT\n",
       "nFeature_RNA                              430.0\n",
       "nCount_RNA                               2375.0\n",
       "barcodes             P1_Normal_CGACTTCCAGCTGGCT\n",
       "patient                                      P1\n",
       "tum.norm                                 Normal\n",
       "celltypes                            Epithelial\n",
       "celltypes_lvl2                   Normal_KC_Diff\n",
       "celltypes_lvl3                   Normal_KC_Diff\n",
       "percent_mito                           4.749009\n",
       "RNA_snn_res.0.2                               0\n",
       "RNA_snn_res.0.4                               0\n",
       "kmeans_14                                     7\n",
       "encoded_celltypes                             5\n",
       "cluster                                       5\n",
       "split                                     train\n",
       "Split_1                                   train\n",
       "Split_2                                   train\n",
       "Split_3                                   train\n",
       "Split_4                                   train\n",
       "Split_5                                    test\n",
       "Name: 2036, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick sanity check for train samples\n",
    "rand_train = np.random.choice(dataset_splits['Split_1']['train'].tolist())\n",
    "print(f'Random test cell: {rand_train}');\n",
    "adata.obs.iloc[rand_train] # supposed to be a 'train cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71dc9c97-3b60-4bd1-94a3-4c4ae7e7e067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random test cell: 5490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "index                P2_Normal_ACTGATGAGCCCAATT\n",
       "nFeature_RNA                              596.0\n",
       "nCount_RNA                               2087.0\n",
       "barcodes             P2_Normal_ACTGATGAGCCCAATT\n",
       "patient                                      P2\n",
       "tum.norm                                 Normal\n",
       "celltypes                            Epithelial\n",
       "celltypes_lvl2                  Normal_KC_Basal\n",
       "celltypes_lvl3                  Normal_KC_Basal\n",
       "percent_mito                           4.696417\n",
       "RNA_snn_res.0.2                               9\n",
       "RNA_snn_res.0.4                              14\n",
       "kmeans_14                                    14\n",
       "encoded_celltypes                             5\n",
       "cluster                                       5\n",
       "split                                     train\n",
       "Split_1                                    test\n",
       "Split_2                                   train\n",
       "Split_3                                   train\n",
       "Split_4                                    test\n",
       "Split_5                                   train\n",
       "Name: 5490, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick sanity check for test samples\n",
    "rand_test = np.random.choice(dataset_splits['Split_1']['test'].tolist())\n",
    "print(f'Random test cell: {rand_test}');\n",
    "adata.obs.iloc[rand_test] # supposed to be a 'test cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "555f7381-c16c-4363-aec4-7f549bd8c105",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.to_csv(f'{metadata_dir}/{dataset_name}_metadata_splits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f57173b-1a81-49d0-81f1-897c6198194b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrnaseq",
   "language": "python",
   "name": "scrnaseq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
